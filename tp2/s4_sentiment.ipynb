{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis \n",
    "\n",
    "## 1. Textblob-FR\n",
    "\n",
    "Documentation: https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une fonction `get_sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "\n",
    "def get_sentiment(input_text):\n",
    "    blob = tb(input_text)\n",
    "    polarity, subjectivity = blob.sentiment\n",
    "    polarity_perc = f\"{100*abs(polarity):.0f}\"\n",
    "    subjectivity_perc = f\"{100*subjectivity:.0f}\"\n",
    "    if polarity > 0:\n",
    "        polarity_str = f\"{polarity_perc}% positive\"\n",
    "    elif polarity < 0:\n",
    "        polarity_str = f\"{polarity_perc}% negative\"\n",
    "    else:\n",
    "        polarity_str = \"neutral\"\n",
    "    if subjectivity > 0:\n",
    "        subjectivity_str = f\"{subjectivity}% subjective\"\n",
    "    else:\n",
    "        subjectivity_str = \"perfectly objective\"\n",
    "    print(f\"This text is {polarity_str} and {subjectivity_str}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser le sentiment d'une phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir une année\n",
    "year = 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister les fichiers de cette année\n",
    "data_path = '../data'\n",
    "txt_path = '../data/txt'\n",
    "txts = [f for f in os.listdir(txt_path) if os.path.isfile(os.path.join(txt_path, f)) and str(year) in f]\n",
    "len(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocker le contenu de ces fichiers dans une liste\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(os.path.join(txt_path, txt), 'r', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter le nombre d'éléments (=fichiers) dans la liste\n",
    "len(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste pour stocker les phrases\n",
    "selected_phrases = []\n",
    "\n",
    "# Compteur pour les documents et les phrases\n",
    "document_count = 0\n",
    "phrase_count = 0\n",
    "\n",
    "# Longueur minimale requise pour une phrase\n",
    "min_phrase_length = 30\n",
    "\n",
    "# Parcour des 10 premiers fichiers de la liste\n",
    "for document in content_list[:10]:\n",
    "    # Division du fichier en trois parties égales\n",
    "    part_length = len(document) // 3\n",
    "    \n",
    "    # Phrases au début\n",
    "    start_phrases = []\n",
    "    current_phrase = \"\"\n",
    "    for char in document[:part_length]:\n",
    "        current_phrase += char\n",
    "        if char in ['.', '!', '?']:\n",
    "            if len(current_phrase) >= min_phrase_length:\n",
    "                start_phrases.append(current_phrase)\n",
    "                current_phrase = \"\"\n",
    "    \n",
    "    # Phrases au milieu\n",
    "    middle_phrases = []\n",
    "    current_phrase = \"\"\n",
    "    for char in document[part_length:2*part_length]:\n",
    "        current_phrase += char\n",
    "        if char in ['.', '!', '?']:\n",
    "            if len(current_phrase) >= min_phrase_length:\n",
    "                middle_phrases.append(current_phrase)\n",
    "                current_phrase = \"\"\n",
    "    \n",
    "    # Phrases à la fin\n",
    "    end_phrases = []\n",
    "    current_phrase = \"\"\n",
    "    for char in document[2*part_length:]:\n",
    "        current_phrase += char\n",
    "        if char in ['.', '!', '?']:\n",
    "            if len(current_phrase) >= min_phrase_length:\n",
    "                end_phrases.append(current_phrase)\n",
    "                current_phrase = \"\"\n",
    "    \n",
    "    # Sélection de 3 phrases au début, 3 au milieu et 4 à la fin\n",
    "    selected_phrases.extend(start_phrases[:3])\n",
    "    selected_phrases.extend(middle_phrases[:3])\n",
    "    selected_phrases.extend(end_phrases[:4])\n",
    "    \n",
    "    # Mise à jour des compteurs\n",
    "    document_count += 1\n",
    "    phrase_count += len(start_phrases[:3]) + len(middle_phrases[:3]) + len(end_phrases[:4])\n",
    "    \n",
    "    if phrase_count >= 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " selected_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\\n\".join(selected_phrases[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_sentiment(\"Les journaux publient la dépêche suivante du camp de Frère, 31 : Les Boers ont établi un nouveau camp formé do 63 wagons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_sentiment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utilisation de transformers\n",
    "\n",
    "Documentation: https://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n",
    "\n",
    "**!!** Si le code ne tourne pas sur votre machine, vous pouvez le tester directement sur Google Colab en utilisant [ce lien](https://colab.research.google.com/github/TheophileBlard/french-sentiment-analysis-with-bert/blob/master/colab/french_sentiment_analysis_with_bert.ipynb) **!!**\n",
    "\n",
    "Le modèle peut également être testé en ligne sur [HuggingFace](https://huggingface.co/tblard/tf-allocine)\n",
    "\n",
    "### Installation des librairies et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install spacy-transformer\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\", use_pt=True)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"tblard/tf-allocine\")\n",
    "\n",
    "sentiment_analyser = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser le sentiment d'une phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyser(\"Ce journal est vraiment super intéressant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyser(\"Cette phrase est négative et je ne suis pas content !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tac_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1932ab1d169b4769d1550e799423b6477588e745f266d79d9004c136c81607e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
